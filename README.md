# AI Ethics Auditor🔍

A free and open source toolkit to detect, explain, and mitigate bias in AI/ML models and datasets. Built for developers and researchers committed to ethical AI practices.

![image_grid](https://github.com/user-attachments/assets/c98c964d-5b0c-4a39-adc4-9f48c86d55e8)

Youtube Link: https://youtu.be/hhgAVjn7CsM?si=ms36vvt2yZQJn-8Y

## Overview

AI Ethics Auditor is a standalone tool that analyzes AI models and datasets for hidden biases, generates explainability reports, and suggests mitigations. This MVP is designed as a local web application with a modular architecture that can later integrate as a plugin for Jupyter, VS Code, or ML platforms like Hugging Face.

**Key Principles:**
- **Privacy-First:** All processing is done locally (no external APIs).
- **FOSS Compliance:** Uses open-source libraries and ships under the MIT License.
- **Developer-Centric:** Designed for seamless integration into existing ML workflows.

## Ethical AI Principles & Predefined Criteria

We use established AI ethics guidelines from:
- EU AI Act
- OECD AI Principles
- Fairness Indicators by Google
- IBM AI Fairness 360 Toolkit

## Key Features

### Bias Detection Engine
- Analyze datasets for class imbalances (e.g., gender, race).
- Evaluate models for fairness metrics (e.g., demographic parity, equal opportunity).
- Support for tabular data (CSV) and common ML frameworks (PyTorch, TensorFlow).

### Explainability & Transparency
- Generate SHAP/LIME explanations for model predictions.
- Visualize bias scores and fairness trade-offs with interactive charts.

### Mitigation Toolkit
- Suggest reweighting strategies for biased datasets.
- Recommend fairness-aware algorithms (e.g., adversarial debiasing).

### Modular & Extensible
- Core logic decoupled from UI for future plugin development.
- Configurable fairness thresholds via YAML files.

## Codebase Directory Structure📂

```
ai-ethics-auditor/
│
├── backend/
│   ├── config/
│   │   ├── metrics.yaml
│   │   └── datasets/
│   ├── main.py
│   ├── bias_detector.py
│   ├── explainability.py
│   ├── mitigations.py
│   ├── db_manager.py
│   ├── requirements.txt
│   └── tests/
│       ├── test_bias.py
│       └── test_mitigations.py
│
├── frontend/
│   ├── public/
│   │   ├── index.html         # Main UI (Dashboard)
|   |   ├──analyze.html
|   |   ├──reports.html        
│   │   └── assets/
│   │       ├── styles.css    # CSS styling
│   │       ├── viz.js        # Data visualization
│   │       └── main.js       # API handling & UI updates
│   ├── src/   
│   │   ├── components/
│   │   │   ├── DatasetAnalyzer.py
│   │   │   ├── ModelAuditor.py
│   │   │   ├── FairnessMetrics.py
│   │   │   └── PrivacyTester.py
│   │   └── utils/
│   │       ├── api_client.py
│   │       └── visualizations.py
│   └──package.json
│   
│
├── .gitignore
├── LICENSE
├── setup.py
└── README.md
```

## Installation & Setup

### Prerequisites
- Python 3.8+ with pip
- Node.js 16+ (for custom frontend extensions)
- Git

### Steps
1. **Clone the Repository:**
   ```bash
   git clone https://github.com/yourusername/ai-ethics-auditor
   cd ai-ethics-auditor
   ```

2. **Setup Backend:**
   ```bash
   cd backend
   pip install -r requirements.txt
   uvicorn main:app --reload  # Starts FastAPI server on port 8000
   ```

3. **Setup Frontend:**
   ```bash
   cd ../frontend
   streamlit run app.py  # Launches UI on port 8501
   ```

## Usage

### Analyze a Dataset
1. Upload a CSV via the UI.
2. Select sensitive attributes (e.g., "gender", "race").
3. View fairness metrics and bias scores.

### Audit a Model
1. Load a pretrained model (PyTorch/TensorFlow).
2. Run predictions on test data.
3. Generate SHAP explanations for flagged biases.

### Mitigate & Export
1. Apply reweighting/resampling.
2. Download the debiased dataset or model.
3. Save a PDF report for compliance.

## Tech Stack
- **Backend:** Python, FastAPI, Fairlearn, SHAP, SQLite.
- **Frontend:** Streamlit, Plotly, D3.js.

## Future Roadmap
1. VS Code extension for in-IDE bias checking.
2. NLP bias detection (Hugging Face integration).
3. Automated compliance reporting (PDF/LaTeX).

## Contributing
1. Fork the repository.
2. Create a feature branch (e.g., feature/your-feature).
3. Submit a PR with tests and documentation.
4. Join our discussions for major changes.

## Support
- Open an issue or email humblecreators500@gmail.com for support.
- Join our community discussions for general questions.

## License
This project is licensed under the **MIT License**. See the [LICENSE](./LICENSE) file for details.

---

Empower ethical AI – one audit at a time!
